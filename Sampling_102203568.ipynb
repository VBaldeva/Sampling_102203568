{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGtoF6cbZTuZ",
        "outputId": "2ab78506-4403-402a-a8f9-7dbd9a2a1d14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:21:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:21:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:21:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:21:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:21:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Results (in %):\n",
            "   Sampling 1 Sampling 2 Sampling 3 Sampling 4 Sampling 5\n",
            "M1      87.74      69.03      89.68      89.03      89.68\n",
            "M2      98.71      75.48      98.71      98.71      98.71\n",
            "M3      98.71       80.0      98.06      98.06      97.42\n",
            "M4      83.23      70.32      60.65      60.65      63.87\n",
            "M5      96.13      71.61      76.13      75.48      76.77\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "# Replace the file path with the actual path to your dataset\n",
        "data = pd.read_csv(\"/content/Creditcard_data.csv\")\n",
        "\n",
        "# Step 2: Separate features (X) and target (y)\n",
        "X = data.drop(columns=[\"Class\"])\n",
        "y = data[\"Class\"]\n",
        "\n",
        "# Step 3: Split the data into train and test sets with stratification\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=3568, stratify=y\n",
        ")\n",
        "\n",
        "# Step 4: Define sampling techniques\n",
        "sampling_methods = {\n",
        "    \"Sampling 1\": RandomOverSampler(random_state=3568),\n",
        "    \"Sampling 2\": RandomUnderSampler(random_state=3568),\n",
        "    \"Sampling 3\": SMOTE(random_state=3568),\n",
        "    \"Sampling 4\": SMOTETomek(random_state=3568),\n",
        "    \"Sampling 5\": ADASYN(random_state=3568),\n",
        "}\n",
        "\n",
        "# Step 5: Define machine learning models\n",
        "models = {\n",
        "    \"M1\": LogisticRegression(max_iter=1111, random_state=3568),\n",
        "    \"M2\": RandomForestClassifier(random_state=3568),\n",
        "    \"M3\": XGBClassifier(\n",
        "        use_label_encoder=False, eval_metric=\"logloss\", random_state=3568),\n",
        "    \"M4\": SVC(probability=True, random_state=3568),\n",
        "    \"M5\": KNeighborsClassifier(),\n",
        "}\n",
        "\n",
        "# Step 6: Create a DataFrame to store results\n",
        "results_df = pd.DataFrame(index=models.keys(), columns=sampling_methods.keys())\n",
        "\n",
        "# Step 7: Apply sampling techniques and train models\n",
        "for sampling_name, sampler in sampling_methods.items():\n",
        "    # Apply sampling to the training data\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Train the model on resampled data\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        # Store the accuracy in the results DataFrame (as percentage)\n",
        "        results_df.loc[model_name, sampling_name] = round(accuracy * 100, 2)\n",
        "\n",
        "# Step 8: Display the results\n",
        "print(\"Accuracy Results (in %):\")\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1fO6oWYaKrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}